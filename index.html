<!-- This entire file shamelessly stolen as-is from Jon Barron's website: http://www.cs.berkeley.edu/~barron/ -->

<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<!-- saved from url=(0035)http://www.cs.berkeley.edu/~barron/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
  <meta name="viewport" content="width=800">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
  /* Color scheme stolen from Sergey Karayev */
  a {
    color: #1772d0;
    text-decoration:none;
  }
  a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
  }
  body,td,th,tr,p,a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px
  }
  strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
  }
  heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 22px;
  }
  papertitle {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    font-weight: 700
  }
  name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 32px;
  }
  .one
  {
    width: 160px;
    height: 160px;
    position: relative;
  }
  .two
  {
    width: 160px;
    height: 160px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
  }
  .fade {
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
  }
  </style>
  <link rel="icon" type="image/png" href="http://umich.edu/skins/um2013/media/images/touch-icon-iphone.png">
  <title>Abhishek Venkataraman</title>

  <link href="./css" rel="stylesheet" type="text/css">
</head>
<body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tbody><tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody><tr>
            <td width="67%" valign="middle">
              <p align="center">
		      <name>Abhishek <b>Venkataraman</b></name><br>
              </p>
              <p>I am a second year master's student at the <a href="http://www.eecs.umich.edu/">University of Michigan</a>
		where I am working with <a href="http://ai.eecs.umich.edu/people/laird/index.html">John Laird</a>
                and <a href = "http://web.eecs.umich.edu/~jjcorso/">Jason Corso</a> as part of the
		<a href="http://www.eecs.umich.edu/ai/">Artificial Intelligence Laboratory</a>.
              </p>
              <p>
                Prior to coming to Michigan, I got my undergraduate degree at <a href="http://www.gatech.edu">Georgia Tech</a>, 
                where I worked with <a href="https://my.vanderbilt.edu/mkunda/">Maithilee Kunda</a> in computer science, 
                and with <a href="https://www.ece.gatech.edu/faculty-staff-directory/omer-t-inan">Omer Inan</a>
                and  <a href="http://www.sulchek2.gatech.edu/people/todd-sulchek/">Todd Sulchek</a> in biomedical engineering.</p>
                <p align="center">
                  <a href="mailto:mbanani@umich.edu">Email</a> &nbsp;/&nbsp;
                  <a href="https://mbanani.github.io/elbanani_cv.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=Iwe1QVEAAAAJ&hl">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/mbanani">GitHub</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/mohamedbanani/">LinkedIn</a>
                </p>
              </td>
              <td width="33%">
                <img src="./abhishek_low.png">
              </td>
            </tr>
          </tbody></table>

          <!--  News -->
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody><tr>
              <td width="100%" valign="middle">
                <heading>News</heading>
                <p>
                    <ul>
                        <li>09/2017: I released a PyTorch implementation of <a href="https://arxiv.org/abs/1703.09859">Clickhere CNN</a> and <a href="https://arxiv.org/abs/1505.05641">Render For CNN</a> . 
                            (<a href="https://github.com/mbanani/pytorch-clickhere-cnn">code</a>) </li>
                        <li>06/2017: I gave a talk at the 37th Soar workshop on my current research project. 
                            (<a href="https://soar.eecs.umich.edu/workshop/37/files/Visual%20Guidance%20through%20Reasoning.pdf">slides</a>) </li>
                        <li>06/2016: I gave a talk at the 36th Soar workshop on the block design task project. 
                            (<a href="https://soar.eecs.umich.edu/workshop/36/files/El%20Banani%20-%20Perception,%20Attention%20and%20Problem%20Solving%20on%20Block%20Design.pdf">slides</a>) </li>
                        <li>07/2016: I presented a poster at CogSci 2016. (<a href="https://pdfs.semanticscholar.org/554f/902e04ebe1cdddf00fd1e5f1dd44e276d137.pdf">paper</a>) </li>
                    </ul> 
                </p>
              </td>
            </tr>
          </tbody></table>
          
        <!--  Research -->
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody><tr>
              <td width="100%" valign="middle">
                <heading>Research</heading>
                <p>
                  I am interested in the problems that lie at the intersection of computer vision and cognitive science.
                  I am currently working on tackling the following question,
		  can an agent use its reasoning and interaction capabilities to improve its perception? 
		  I am approaching this question by exploring possible integrations between convolutional neural networks and the Soar cognitive architecture.
                </p>
<!--                 <p>
                    I organize the <a href="./reading.html"> Computational Cognitive Science reading group</a>.
                </p> -->
              </td>
            </tr>
          </tbody></table>

          <!-- Previous Projects -->
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody><tr>
              <td width="100%" valign="middle">
                <heading>Previous Projects</heading>
              </td>
            </tr>
          </tbody></table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody><tr>
              <td width="30%">
                <img src="./Kohs_CogSci_2016.png" width="100%">
              </td>

              <td valign="top" width="70%">
                <p><a href="https://pdfs.semanticscholar.org/554f/902e04ebe1cdddf00fd1e5f1dd44e276d137.pdf">
                  <papertitle>A Computational Exploration of Problem-Solving Strategies and Gaze Behaviors on the Block Design Task</papertitle></a><br>
                   <a href="https://my.vanderbilt.edu/mkunda/">Maithilee Kunda</a>,
                   <strong>Mohamed El Banani</strong>,
                   <a href="http://rehg.org/">James M. Rehg</a>
                   <br>
                   <!-- Journal -->
                  <em>38th Annual Conference of the Cognitive Science Society</em>, 2016<br>
                  <!-- Additional Links -->
                </p><p></p>
                <p>
                  We present a computational architecture that is used
                  to compare different models of problem-solving on the block
                  design task and to generate detailed behavioral predictions for
                  each different strategy. We describe the results of three different
                  modeling experiments and discuss how these results provide
                  greater insight into the analysis of gaze behavior and error
                  patterns on the block design task.

                </p><p></p>
                <p></p>
              </td>
            </tr>
          </tbody>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody><tr>
              <td width="30%">
                <img src="./Inan_BCG.jpg" width="100%">
              </td>

              <td valign="top" width="70%">
                <p><a href="http://www.sciencedirect.com/science/article/pii/S0735109716314565?_rdoc=1&_fmt=high&_origin=gateway&_docanchor=&md5=b8429449ccfc9c30159a5f9aeaa92ffb">
                  <papertitle>A Pilot Study of a Modified Bathroom Scale to Monitor Cardiovascular Hemodynamic in Pregnancy</papertitle></a><br>
                   Odayme Quesada,
                   <strong>Mohamed El Banani</strong>,
                   James Heller,
                   Shire Beach,
                   Mozziyar Etemadi,
                   Shuvo Roy,
                   <a href="https://www.ece.gatech.edu/faculty-staff-directory/omer-t-inan">Omer Inan</a>,
                   Juan Gonzalez,
                   Liviu Klein
                   <br>
                   <!-- Journal -->
                  <em>Journal of the American College of Cardiology</em>, 2016<br>
                  <!-- Additional Links -->
                </p><p></p>
                <p>
                  We showed that the ballistocardiogram (BCG) signal - the heart beat induced repetitive movements of the
                  body due to acceleration of blood as it is ejected into the large vessels - can be measured using a modified bathroom scale.
                  We used the scale to acquire serial measurements of BCG waveforms during pregnancy to assess maternal cardiovascular adaptation
                  , including changes in cardiac output (CO), cardiac contractility (CC) and heart rate (HR).

                </p><p></p>
                <p></p>
              </td>
            </tr>
          </tbody></table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody><tr>
              <td width="30%">
                <img src="./Sulchek_3D.jpg" width="100%">
              </td>

              <td valign="top" width="70%">
                <p><a href="http://www.sciencedirect.com/science/article/pii/S0955598615000722">
                  <papertitle>Three-Dimensional Particle Tracking in Microfluidic Channel Flow using In and Out of Focus Diffraction</papertitle></a><br>
                    Bushra Tasadduq,
                    Gonghao Wang,
                    <strong>Mohamed El Banani</strong>,
                    Wenbin Mao,
                    Wilbur Lam,
                    Alexander Alexeev,
                    <a href="http://www.sulchek2.gatech.edu/people/todd-sulchek/">Todd Sulchek</a>
                   <br>
                   <!-- Journal -->
                  <em>Journal of Flow Measurement and Instrumentation</em>, 2015<br>
                  <!-- Additional Links -->
                </p><p></p>
                <p>
                  Three-dimensional particle tracking is important to accurately understand the motion of particles within complex flow fields.
                  We show that three-dimensional trajectories of particles within microfluidic flow can be extracted from two-dimensional bright
                  field video microscopy. The method utilizes the defocusing that occurs as particles move out of the objective focal plane when
                  viewed through a high numerical aperture objective lens.
                </p><p></p>
                <p></p>
              </td>
            </tr>
          </tbody></table>


      <!--  Cool Animation-->
      <!-- <tbody><tr onmouseout="clock_stop()" onmouseover="clock_start()">
        <td width="25%">

          <div class="one">
            <div class="two" id="clock_image" style="opacity: 0;"><img src="./cscapes_seg_cropped.png"></div>
            <img src="./cscapes_img_cropped.png">
          </div>
          <script type="text/javascript">
          function clock_start() {
            document.getElementById('clock_image').style.opacity = "1";
          }
          function clock_stop() {
            document.getElementById('clock_image').style.opacity = "0";
          }
          clock_stop()
          </script> -->

          <!-- Teaching

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody><tr>
          <td>
          <heading>Teaching</heading>
        </td>
      </tr>
    </tbody></table>
    <table width="100%" align="center" border="0" cellpadding="20">
    <tbody><tr>
    <td width="75%" valign="center">
    <p>
    <papertitle>CS70 - Summer 2014 (Teaching Assistant)</papertitle>
    <p> <i>Discrete Mathematics for Computer Science</i> covers proof techniques, modular arithmetic, polynomials, and probability.
  </p>
</p>
<p>
<papertitle>EE40 - Summer 2013 (Teaching Assistant)</papertitle>
<p> <i>Introduction to Circuits</i> covers analyzing, designing, and building electronic circuits using op amps and passive components. (Note this class along with EE20 have been replaced by the EE16A/B series as of Fall 2015.)</p>
</p>
</td>
</tr>
</tbody></table>
-->

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tbody><tr>
    <td>
      <br>
      <p align="right"><font size="2">
        <a href="http://www.cs.berkeley.edu/~barron/">(This guy made my life easy)</a>
      </td>
    </tr>
  </tbody>
</table>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-101911550-1', 'auto');
  ga('send', 'pageview');

</script>
</td>
</tr>
</tbody></table>


</body></html>
